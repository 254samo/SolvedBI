{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DATA602_Proj_ImplementingMLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOdjocpMNMOoKVGkSvTunii"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "COGO5yPjhugx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcGuMX6JBjst",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "43758894-76f2-4499-bdf3-d11494c729d1"
      },
      "source": [
        "#Importing dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime as dt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import roc_auc_score,log_loss,accuracy_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm,tqdm_notebook,_tqdm_notebook\n",
        "tqdm.pandas()\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.*` instead of `tqdm._tqdm_notebook.*`\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8fS5FZspekj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Prepping the data\n",
        "url='https://raw.githubusercontent.com/254samo/SolvedBI/master/On_Time_Performance.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "df = df[df['Facility']=='JFK']\n",
        "df = df.reset_index()\n",
        "del df['index']\n",
        "\n",
        "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
        "#df.head()\n",
        "\n",
        "df['month'] = df['Date'].dt.month\n",
        "df['weekday'] = df['Date'].dt.day_name()\n",
        "#df.head()\n",
        "\n",
        "df['80% or More On Time'] = 0\n",
        "df.loc[df['% On-Time Gate Arrivals'] >= 80, '80% or More On Time'] = 1\n",
        "\n",
        "df['month'] = df['month'].apply(str)\n",
        "df = df.drop(['Facility'], axis=1)\n",
        "#df.head()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3Q3a57i4M7y",
        "colab_type": "text"
      },
      "source": [
        "Extracting the Peak Hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ6mZf0p4G8L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extracting the Peak Hours \n",
        "peakHours = df.loc[((df['Hour']>=6) & (df['Hour']<= 9)) | ((df['Hour'] >= 15) & (df['Hour']<= 18)) | ((df['Hour']>= 20)) | ((df['Hour']<= 1))]\n",
        "peakHours = peakHours.drop(['Average Gate Arrival Delay', 'Scheduled Departures', 'Scheduled Arrivals', 'Date', '% On-Time Gate Arrivals', 'Average Gate Departure Delay', 'Hour', 'month', 'weekday'], axis=1)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG6K6NaFkREB",
        "colab_type": "text"
      },
      "source": [
        "Extracting the Off-Peak Hours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLtrDtQPs2cz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "93297ed0-0e31-4ef6-a9d0-99a604862eed"
      },
      "source": [
        "#Extracting the Off-Peak Hours \n",
        "offPeak = df.loc[((df['Hour']>=2) & (df['Hour']<= 5)) | ((df['Hour'] >= 10) & (df['Hour']<= 14)) | ((df['Hour']== 19))]\n",
        "offPeak = offPeak.drop(['Average Gate Arrival Delay', 'Scheduled Departures', 'Scheduled Arrivals', 'Date', '% On-Time Gate Arrivals', 'Average Gate Departure Delay', 'Hour', 'month', 'weekday'], axis=1)\n",
        "\n",
        "offPeak.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Departures For Metric Computation</th>\n",
              "      <th>Arrivals For Metric Computation</th>\n",
              "      <th>% On-Time Gate Departures</th>\n",
              "      <th>% On-Time Airport Departures</th>\n",
              "      <th>Average Taxi Out Time</th>\n",
              "      <th>Average Taxi Out Delay</th>\n",
              "      <th>Average Airport Departure Delay</th>\n",
              "      <th>Average Airborne Delay</th>\n",
              "      <th>Average Taxi In Delay</th>\n",
              "      <th>Average Block Delay</th>\n",
              "      <th>80% or More On Time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>16.00</td>\n",
              "      <td>1.08</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.70</td>\n",
              "      <td>2.00</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>5.70</td>\n",
              "      <td>3.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.00</td>\n",
              "      <td>100.00</td>\n",
              "      <td>16.50</td>\n",
              "      <td>1.20</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>87.50</td>\n",
              "      <td>87.50</td>\n",
              "      <td>22.50</td>\n",
              "      <td>6.00</td>\n",
              "      <td>22.50</td>\n",
              "      <td>5.33</td>\n",
              "      <td>4.92</td>\n",
              "      <td>4.81</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>22.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>81.82</td>\n",
              "      <td>77.27</td>\n",
              "      <td>28.86</td>\n",
              "      <td>11.52</td>\n",
              "      <td>34.14</td>\n",
              "      <td>2.20</td>\n",
              "      <td>1.84</td>\n",
              "      <td>1.96</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>33.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>84.85</td>\n",
              "      <td>84.85</td>\n",
              "      <td>21.61</td>\n",
              "      <td>4.21</td>\n",
              "      <td>9.70</td>\n",
              "      <td>1.06</td>\n",
              "      <td>3.23</td>\n",
              "      <td>0.44</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23.0</td>\n",
              "      <td>31.0</td>\n",
              "      <td>78.26</td>\n",
              "      <td>78.26</td>\n",
              "      <td>19.91</td>\n",
              "      <td>3.75</td>\n",
              "      <td>39.26</td>\n",
              "      <td>1.35</td>\n",
              "      <td>2.17</td>\n",
              "      <td>1.29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>24.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>91.67</td>\n",
              "      <td>83.33</td>\n",
              "      <td>23.00</td>\n",
              "      <td>5.85</td>\n",
              "      <td>8.79</td>\n",
              "      <td>2.17</td>\n",
              "      <td>2.93</td>\n",
              "      <td>3.08</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>30.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>70.00</td>\n",
              "      <td>56.67</td>\n",
              "      <td>23.43</td>\n",
              "      <td>6.23</td>\n",
              "      <td>34.80</td>\n",
              "      <td>3.02</td>\n",
              "      <td>2.79</td>\n",
              "      <td>1.54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>40.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>57.50</td>\n",
              "      <td>35.00</td>\n",
              "      <td>31.35</td>\n",
              "      <td>13.22</td>\n",
              "      <td>32.78</td>\n",
              "      <td>3.25</td>\n",
              "      <td>10.30</td>\n",
              "      <td>8.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Departures For Metric Computation  ...  80% or More On Time\n",
              "2                                 5.0  ...                    1\n",
              "3                                 0.0  ...                    0\n",
              "4                                 2.0  ...                    0\n",
              "5                                 8.0  ...                    1\n",
              "10                               22.0  ...                    1\n",
              "11                               33.0  ...                    1\n",
              "12                               23.0  ...                    1\n",
              "13                               24.0  ...                    1\n",
              "14                               30.0  ...                    1\n",
              "19                               40.0  ...                    0\n",
              "\n",
              "[10 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG14BnBOSalb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To pass parameters to the MLP, enter the the classification feature's name to the \"the_class_column\"\n",
        "the_class_column = '80% or More On Time'\n",
        "#Specify a desired Loss Rate\n",
        "Loss_Rate = 0.0003 #0.0003\n",
        "# Specify the epoch\n",
        "Epochs = 50\n",
        "# Specify the Batch Size\n",
        "BatchSize = 4\n",
        "# Specify the number of neurons for Hidden Layer one and Hidden Layer two\n",
        "NoOfHiddenNeuronsLayer1 = 32\n",
        "NoOfHiddenNeuronsLayer2 = 16"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6h7N9sl-mzOO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "#                       DO NOT EDIT THIS CELL\n",
        "#!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "def perceptron_prep_and_implementation(filename):\n",
        "    data = filename\n",
        "    \n",
        "    \n",
        "    #Suppressing warnings and infos of TensorFlow\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "    SEED = 1000 #Fixing seed\n",
        "    synthetic = False# whether to use synthetic data\n",
        "\n",
        "    def seed_everything(seed=SEED):\n",
        "\t    random.seed(seed)\n",
        "\t    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\t    np.random.seed(seed)\n",
        "\t    tf.set_random_seed(seed) #tf.random.set_seed(seed)\n",
        "    seed_everything(seed=SEED)\n",
        "\n",
        "\t# THIS MARKS THE BEGINNING OF OUR PERCEPTION PREP\n",
        "\t#We assign the dataframe to be processed to the dataframe name that is used in the perceptron\n",
        "\t\n",
        "\t\n",
        "\n",
        "    # HyperParameters\n",
        "    lr = Loss_Rate\n",
        "    training_epochs = Epochs\n",
        "    batch_size = BatchSize\n",
        "    pred_size = int(batch_size * 2)\n",
        "\n",
        "\n",
        "\t\n",
        "\t\n",
        "\t#Shuffling data and resetting index\n",
        "    data = shuffle(data)\n",
        "    data = data.reset_index(drop=True)\n",
        "\t\n",
        "\t#Now since data preparation is done, we assign the index to the class_column variable to a parameter\n",
        "    the_class_column_index = data.columns.get_loc(the_class_column)\n",
        "\n",
        "    # Get the Count of Rows and Columns in data\n",
        "    total_rows_in_data = int(len(data.axes[0]))\n",
        "    total_cols_in_data = int(len(data.axes[1]))\n",
        "\n",
        "    #Separating input and output\n",
        "    X = data.iloc[:, :total_cols_in_data]\n",
        "    X.drop(X.columns[the_class_column_index], axis=1, inplace=True )\n",
        "    y = data.iloc[:, the_class_column_index]\n",
        "\n",
        "    # Get the Count of Columns in the shuffled X and y\n",
        "    total_cols_in_X = int(len(X.axes[1]))\n",
        "    total_cols_in_y = int(1)\n",
        "\n",
        "    # Get the Count of Records in the shuffled X and y\n",
        "    total_rows_in_X = int(len(X.axes[0]))\n",
        "    total_rows_in_y = int(len(y.axes[0]))\n",
        "\n",
        "    if synthetic:\n",
        "        X = np.random.randn(total_rows_in_X,total_cols_in_X)\n",
        "        y = np.random.randn(total_rows_in_y,total_cols_in_y)\n",
        "\n",
        "        #  y = np.where(y[:,0]<0,1)\n",
        "        X,y = shuffle(X,y)\n",
        "\n",
        "    \n",
        "    # Get the Count of Columns in the shuffled X and y\n",
        "    total_cols_in_X = int(len(X.axes[1]))\n",
        "    total_cols_in_y = int(1)\n",
        "\n",
        "    # Get the Count of Records in the shuffled X and y\n",
        "    total_rows_in_X = int(len(X.axes[0]))\n",
        "    total_rows_in_y = int(len(y.axes[0]))\n",
        "\n",
        "    print(X.shape[0],y.shape[0])\n",
        "    #Train data\n",
        "    train_X = X[:int(total_rows_in_X*0.8)]\n",
        "    train_y = y[:int(total_rows_in_y*0.8)]\n",
        "    #Test data\n",
        "    test_X = X[int(total_rows_in_X*0.8):]\n",
        "    test_y = y[int(total_rows_in_y*0.8):]\n",
        "\n",
        "    #Scaling\n",
        "    sc_X = StandardScaler()\n",
        "    train_X = sc_X.fit_transform(train_X)\n",
        "    test_X = sc_X.transform(test_X)\n",
        "\n",
        "    #converting y to one hot formats\n",
        "    train_y = pd.get_dummies(train_y).values\n",
        "    test_y = pd.get_dummies(test_y).values\n",
        "\n",
        "    #5 fold validation\n",
        "    folds = KFold(n_splits= 5, shuffle=True, random_state=SEED)\n",
        "\n",
        "\n",
        "    # Network Parameters\n",
        "    n_hidden_1 = NoOfHiddenNeuronsLayer1 #number of neurons in 1st layer \n",
        "    n_hidden_2 = NoOfHiddenNeuronsLayer2 #number of neurons in 2nd layer \n",
        "    n_input = total_cols_in_X #No of columns/Features in X\n",
        "    n_classes = y.nunique() #Output classes\n",
        "\n",
        "    if synthetic:\n",
        "        n_hidden_1 = 2048\n",
        "        n_hidden_2 = 1024\n",
        "        n_classes = 2\n",
        "        batch_size = 4096\n",
        "        pred_size = 8192\n",
        "    steps = len(train_X) # How many training data\n",
        "\n",
        "    #Resetting the graph\n",
        "    tf.compat.v1.get_default_graph() #tf.reset_default_graph()\n",
        "\n",
        "    #Defining Placeholders\n",
        "    X = tf.placeholder(\"float\", [None, n_input])\n",
        "    Y = tf.placeholder(\"float\", [None, n_classes])\n",
        "    hold_prob1 = tf.placeholder(tf.float32)\n",
        "    hold_prob2 = tf.placeholder(tf.float32)\n",
        "\n",
        "    # Store layers weight & bias\n",
        "    weights = {\n",
        "        'h1': tf.Variable(tf.truncated_normal([n_input, n_hidden_1],\\\n",
        "            mean = 0.0,stddev=0.2)),\n",
        "        'h2': tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2],\\\n",
        "            mean = 0.0,stddev = 0.2)),\n",
        "        'out': tf.Variable(tf.truncated_normal([n_hidden_2, n_classes],\\\n",
        "            mean = 0.0,stddev = 0.2))\n",
        "    }\n",
        "    biases = {\n",
        "        'b1': tf.Variable(tf.constant(0.1,shape = [n_hidden_1])),\n",
        "        'b2': tf.Variable(tf.constant(0.1,shape = [n_hidden_2])),\n",
        "        'out': tf.Variable(tf.constant(0.1,shape = [n_classes]))\n",
        "    }\n",
        "\n",
        "    # Create model\n",
        "    def multilayer_perceptron(x):\n",
        "        # First Hidden Layer\n",
        "        layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "        #Applying RELU nonlinearity\n",
        "        layer1_RELU = tf.nn.relu(layer_1)\n",
        "        #Applying Dropout\n",
        "        layer1_dropout = tf.nn.dropout(layer1_RELU,keep_prob=hold_prob1)\n",
        "        # Second hidden layer\n",
        "        layer_2 = tf.add(tf.matmul(layer1_dropout, weights['h2']), biases['b2'])\n",
        "        #Applying TANH nonlinearity\n",
        "        layer2_TANH = tf.nn.tanh(layer_2)\n",
        "        #Applying Dropout\n",
        "        layer2_dropout = tf.nn.dropout(layer2_TANH,keep_prob=hold_prob2)\n",
        "        # Output layer\n",
        "        out_layer = tf.matmul(layer2_dropout, weights['out']) + biases['out']\n",
        "        return out_layer\n",
        "\n",
        "\n",
        "    # Building model\n",
        "    logits = multilayer_perceptron(X)\n",
        "\n",
        "    # Defining Loss Function\n",
        "    loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "        logits=logits, labels=Y))\n",
        "    #Defining optimizer\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=lr)\n",
        "    #Defining what to minimize\n",
        "    train_op = optimizer.minimize(loss_op)\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    #Graph equations for Accuracy\n",
        "    matches = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
        "    acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "    remaining_train = len(train_X) % batch_size\n",
        "    remaining_test= len(test_X) % pred_size\n",
        "\n",
        "    # Create arrays and dataframes to store results\n",
        "    oof_preds = np.zeros(( train_X.shape[0] , n_classes ) )\n",
        "    sub_preds = np.zeros(( test_X.shape[0] , n_classes ) )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #Opening our Session\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        #k-fold validation\n",
        "        for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train_X,train_y)):\n",
        "            print( \"Fold {} has started\".format(n_fold) )\n",
        "            X_train, y_train = train_X[train_idx], train_y[train_idx]\n",
        "            X_cv, y_cv = train_X[valid_idx], train_y[valid_idx]\n",
        "            #Running initialization of variables\n",
        "            sess.run(init)\n",
        "            # Writing down the for loop for epochs\n",
        "            for epoch in tqdm(range(training_epochs)):\n",
        "                #For loop for batches\n",
        "                for i in range(0,steps - remaining_train , batch_size):\n",
        "                    #Getting training data to be fed into the graphs\n",
        "                    batch_x, batch_y = X_train[i:i+batch_size],y_train[i:i+batch_size]\n",
        "                    # Training batch by batch\n",
        "                    _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,Y: batch_y,\\\n",
        "                        hold_prob1:0.7,hold_prob2:0.8})\n",
        "                \n",
        "                #Feeding last batch of train data\n",
        "                batch_x, batch_y = X_train[-remaining_train:],y_train[-remaining_train:]\n",
        "                _, c = sess.run([train_op, loss_op], feed_dict={X: batch_x,Y: batch_y,\\\n",
        "                    hold_prob1:0.7,hold_prob2:0.8})\n",
        "\n",
        "            #Calculating predictions over validation data\n",
        "            remaining_cv = len(X_cv) % pred_size\n",
        "            preds_on_cv = list()\n",
        "\n",
        "            for j in range(0,len(X_cv) - remaining_cv,pred_size):\n",
        "                batch_x = X_cv[j:j+pred_size]\n",
        "                preds_on_cv_temp = tf.nn.softmax(logits).eval(\n",
        "                    feed_dict ={X: batch_x,hold_prob1:1.0, hold_prob2:1.0})\n",
        "                preds_on_cv_temp = list(preds_on_cv_temp)\n",
        "                preds_on_cv.extend(preds_on_cv_temp)\n",
        "\n",
        "            #Calculating predictions over last batch of CV data\n",
        "            if remaining_cv != 0:\n",
        "                batch_x = X_cv[-remaining_cv:]\n",
        "                preds_on_cv_temp = tf.nn.softmax(logits).eval(\n",
        "                        feed_dict ={X: batch_x,hold_prob1:1.0, hold_prob2:1.0})\n",
        "                preds_on_cv_temp = list(preds_on_cv_temp)\n",
        "                preds_on_cv.extend(preds_on_cv_temp)\n",
        "\n",
        "            #Calculating loss and accuracy for CV\n",
        "            acc_on_cv,loss_on_cv = sess.run([acc,loss_op],feed_dict ={X: X_cv, Y: y_cv,\\\n",
        "                hold_prob1:1.0, hold_prob2:1.0})\n",
        "            #Calculating AUC on Cross Validation data\n",
        "            auc_on_cv = roc_auc_score(y_cv,preds_on_cv)\n",
        "            #Printing CV statistics after each epoch\n",
        "            print(\" Accuracy: \",acc_on_cv,\"\\n Loss: \",loss_on_cv,\"\\n AUC: \",auc_on_cv)\n",
        "            \n",
        "            #Calculating predictions over test data\n",
        "            preds_on_test = list()\n",
        "            for j in range(0,len(test_X) - remaining_test,pred_size):\n",
        "                batch_x = test_X[j:j+pred_size]\n",
        "                preds_on_test_temp = tf.nn.softmax(logits).eval(\n",
        "                    feed_dict ={X: batch_x,hold_prob1:1.0, hold_prob2:1.0})\n",
        "                preds_on_test_temp = list(preds_on_test_temp)\n",
        "                preds_on_test.extend(preds_on_test_temp)\n",
        "            #Calculating predictions over last batch of test data\n",
        "            if remaining_test != 0:\n",
        "                batch_x = test_X[-remaining_test:]\n",
        "                preds_on_test_temp = sess.run(tf.nn.softmax(logits),\\\n",
        "                        feed_dict ={X: batch_x,hold_prob1:1.0, hold_prob2:1.0})\n",
        "                preds_on_test_temp = list(preds_on_test_temp)\n",
        "                preds_on_test.extend(preds_on_test_temp)\n",
        "        oof_preds[valid_idx] = np.array(preds_on_cv)\n",
        "        sub_preds += np.array(preds_on_test) / folds.n_splits\n",
        "        print(\"\\n Validation Results: \")\n",
        "        print(\" Accuracy: \",acc_on_cv,\"\\n Loss: \",loss_on_cv,\"\\n AUC: \",auc_on_cv)\n",
        "    print(\"\\n Training and Scoring on Validation data done\")\n",
        "\n",
        "\n",
        "    acc_on_test = accuracy_score(test_y.argmax(axis=1),sub_preds.argmax(axis=1))\n",
        "    loss_on_test = log_loss(test_y,sub_preds)\n",
        "    auc_on_test = roc_auc_score(test_y,sub_preds)\n",
        "    print(\"\\n Test Results are below: \")\n",
        "    print(\" Accuracy: \",acc_on_test,\" \\n Loss: \",loss_on_test,\" \\n AUC: \",auc_on_test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DPK-cHuuUle",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        },
        "outputId": "a6cca129-4df8-4ee5-dcdb-9d69ffa624e4"
      },
      "source": [
        "perceptron_prep_and_implementation(peakHours)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1288 1288\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/dispatch.py:201: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/rmsprop.py:123: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "Fold 0 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:09<00:00,  5.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.74271846 \n",
            " Loss:  0.48532787 \n",
            " AUC:  0.8332829960736938\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:09,  5.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 1 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:09<00:00,  5.51it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.7330097 \n",
            " Loss:  0.49351275 \n",
            " AUC:  0.8507081038552322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:08,  5.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 2 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:09<00:00,  5.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.79611653 \n",
            " Loss:  0.41431913 \n",
            " AUC:  0.8808441558441559\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:08,  5.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 3 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:09<00:00,  5.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.7815534 \n",
            " Loss:  0.5015647 \n",
            " AUC:  0.8259242957746479\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:09,  5.21it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 4 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:09<00:00,  5.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.776699 \n",
            " Loss:  0.45959997 \n",
            " AUC:  0.8496848739495798\n",
            "\n",
            " Validation Results: \n",
            " Accuracy:  0.776699 \n",
            " Loss:  0.45959997 \n",
            " AUC:  0.8496848739495798\n",
            "\n",
            " Training and Scoring on Validation data done\n",
            "\n",
            " Test Results are below: \n",
            " Accuracy:  0.7829457364341085  \n",
            " Loss:  0.4811073233833319  \n",
            " AUC:  0.8621434470491074\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlYEPUa26kjY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "outputId": "1ca9fff4-bfba-46cc-c9bd-4aa93773ff34"
      },
      "source": [
        "perceptron_prep_and_implementation(offPeak)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "920 920\n",
            "Fold 0 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  7.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.6891892 \n",
            " Loss:  0.56459427 \n",
            " AUC:  0.7674632352941176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:06,  7.45it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 1 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  7.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.64625853 \n",
            " Loss:  0.58278996 \n",
            " AUC:  0.7605421686746988\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:06,  7.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 2 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  7.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.71428573 \n",
            " Loss:  0.541843 \n",
            " AUC:  0.8072998430141287\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:06,  7.61it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 3 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  7.42it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.64625853 \n",
            " Loss:  0.65516 \n",
            " AUC:  0.6951492537313433\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  2%|▏         | 1/50 [00:00<00:06,  7.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fold 4 has started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 50/50 [00:06<00:00,  7.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " Accuracy:  0.6530612 \n",
            " Loss:  0.64701027 \n",
            " AUC:  0.7358385783043317\n",
            "\n",
            " Validation Results: \n",
            " Accuracy:  0.6530612 \n",
            " Loss:  0.64701027 \n",
            " AUC:  0.7358385783043317\n",
            "\n",
            " Training and Scoring on Validation data done\n",
            "\n",
            " Test Results are below: \n",
            " Accuracy:  0.7717391304347826  \n",
            " Loss:  0.45134448875470035  \n",
            " AUC:  0.8680588942307692\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isVYITt_p5XR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}